{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BZWycuLMQEj",
        "outputId": "1f0ef51a-226b-4799-e486-84b17c6c9861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "import sys\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"frankenstein.txt\").read()\n"
      ],
      "metadata": {
        "id": "IqME_xFzYy0a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_words(input):\n",
        "    input = input.lower()\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(input)\n",
        "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "    return \" \".join(filtered)\n",
        "\n",
        "processed_inputs = tokenize_words(file)\n"
      ],
      "metadata": {
        "id": "-k5foNtmdqQg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(processed_inputs)))\n",
        "char_to_num = dict((c, i) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "N0PPaoA8dxMm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print(\"Total No. of Characters: \",input_len)\n",
        "print(\"Total Vocab: \",vocab_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0LmoGsVd4cZ",
        "outputId": "6a3d9d1e-01f2-4772-ae6f-7b7e68e592a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total No. of Characters:  269566\n",
            "Total Vocab:  38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "metadata": {
        "id": "DqbwYKtqfWc3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through the sequence\n",
        "for i in range(0, input_len - seq_length, 1):\n",
        "    in_seq = processed_inputs[i:i + seq_length]\n",
        "    out_seq = processed_inputs[i + seq_length]\n",
        "    x_data.append([char_to_num[char] for char in in_seq])\n",
        "    y_data.append(char_to_num[out_seq])\n",
        "\n",
        "n_patterns = len(x_data)\n",
        "print(\"Total Patterns:\", n_patterns)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qibYGOL-D8j",
        "outputId": "272686bc-d6f3-4ee5-97cf-17c87e0d5729"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns: 269466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert input sequence to np array and so on\n",
        "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X = X / float(vocab_len)"
      ],
      "metadata": {
        "id": "cJriQc3JAzHc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical  # Correct Import\n",
        "\n",
        "# One-hot encoding\n",
        "y = to_categorical(y_data)\n"
      ],
      "metadata": {
        "id": "eX5M8pDMA6oh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6U9sfqAA-sE",
        "outputId": "b3566c37-5a33-4405-b24c-13fd1cebc863"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "metadata": {
        "id": "KIs_qZRuBnvp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"model_weights_saved.keras\"  # Change .hdf5 to .keras\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "desired_callbacks = [checkpoint]\n",
        "\n"
      ],
      "metadata": {
        "id": "wfXKS4JGCYaI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X, y, epochs=4, batch_size=256, callbacks=desired_callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Sgx9RscCD-V-",
        "outputId": "81b638cb-2822-4ffd-8ae3-6c7dc41ae71e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m1052/1053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 2.9523\n",
            "Epoch 1: loss improved from inf to 2.89374, saving model to model_weights_saved.keras\n",
            "\u001b[1m1053/1053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 64ms/step - loss: 2.9521\n",
            "Epoch 2/4\n",
            "\u001b[1m1052/1053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2.6567\n",
            "Epoch 2: loss improved from 2.89374 to 2.61269, saving model to model_weights_saved.keras\n",
            "\u001b[1m1053/1053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 65ms/step - loss: 2.6566\n",
            "Epoch 3/4\n",
            "\u001b[1m1052/1053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 2.4900\n",
            "Epoch 3: loss improved from 2.61269 to 2.46102, saving model to model_weights_saved.keras\n",
            "\u001b[1m1053/1053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 67ms/step - loss: 2.4900\n",
            "Epoch 4/4\n",
            "\u001b[1m1052/1053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 2.3705\n",
            "Epoch 4: loss improved from 2.46102 to 2.34464, saving model to model_weights_saved.keras\n",
            "\u001b[1m1053/1053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 67ms/step - loss: 2.3705\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x781bebb51d90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recompile model with the saved weights\n",
        "filename = \"model_weights_saved.keras\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n"
      ],
      "metadata": {
        "id": "c3xcwUNhEMMn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output of the model back into characters\n",
        "num_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "yG8vVJxlZPOH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = numpy.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed:\")\n",
        "print(\"\\\"\", \"\".join([num_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-NCIqfjZY59",
        "outputId": "bfb56b3e-1e43-4775-c62d-58ee30edcf26"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:\n",
            "\" ll unhappy still avoid society time lost conjecture cause yesterday idea struck well founded conjure \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(vocab_len)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = num_to_char[index]\n",
        "\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O98oNm9pZca3",
        "outputId": "d3be9a95-cff9-48c8-ce97-df3256d38fdc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d sererable serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer serer sere"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "arXK0oX-ZkzA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}